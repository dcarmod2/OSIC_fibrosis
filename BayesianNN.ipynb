{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "from matplotlib import figure  \n",
    "from matplotlib.backends import backend_agg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_probability as tfp\n",
    "import seaborn as sns\n",
    "from natsort import natsorted\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "tfd = tfp.distributions\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dir = 'dicom_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('hcomb_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, tuple)\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, samples):\n",
    "        to_ret = []\n",
    "        for image in samples:\n",
    "            \n",
    "            resize_factor = np.array(self.output_size) / np.array(image.shape)\n",
    "            image = zoom(image, resize_factor, mode='nearest')\n",
    "            to_ret.append(\n",
    "                image    \n",
    "            )\n",
    "        return to_ret\n",
    "    \n",
    "    def fit_transform(self, samples,y=None):\n",
    "        to_ret = []\n",
    "        for image in samples:\n",
    "            \n",
    "            resize_factor = np.array(self.output_size) / np.array(image.shape)\n",
    "            image = zoom(image, resize_factor, mode='nearest')\n",
    "            to_ret.append(\n",
    "                image    \n",
    "            )\n",
    "        return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessData(BaseEstimator,TransformerMixin):\n",
    "    #I'm requiring the user to know in advance the values\n",
    "    #of each categorical variable, since otherwise\n",
    "    #if a subset of the data is missing a category,\n",
    "    #the dummy variables will be incorrect\n",
    "    def __init__(self,numerical_features = [],categorical_encoder = dict(),\n",
    "                feature_adder = None,\n",
    "                set_index = None):\n",
    "        self.numerical_features = numerical_features\n",
    "        self.categorical_encoder = categorical_encoder\n",
    "        self.feature_adder = feature_adder\n",
    "        self.set_index = set_index\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        \n",
    "        if self.feature_adder:\n",
    "            X = self.feature_adder(X)\n",
    "        if self.set_index:\n",
    "            X = X.set_index(self.set_index)\n",
    "        cur_df = X.loc[:,self.numerical_features]\n",
    "        for colname,categories in self.categorical_encoder.items():\n",
    "            cur_col = X.loc[:,colname].values\n",
    "            one_hots = np.eye(len(categories))\n",
    "            cats = {category: one_hots[i] for i,category in enumerate(categories)}\n",
    "            def get_cat(x):\n",
    "                return cats.get(x,None)\n",
    "            \n",
    "            output_arr = np.vstack([get_cat(x) for x in cur_col])\n",
    "            \n",
    "            to_concat = pd.DataFrame(output_arr,index=cur_df.index,columns=categories)\n",
    "            \n",
    "            cur_df = pd.concat([cur_df,to_concat],axis=1)\n",
    "        return cur_df\n",
    "    \n",
    "    def fit_transform(self,X,y=None):\n",
    "        \n",
    "        if self.feature_adder:\n",
    "            X = self.feature_adder(X)\n",
    "        if self.set_index:\n",
    "            X = X.set_index(self.set_index)\n",
    "        cur_df = X.loc[:,self.numerical_features]\n",
    "        for colname,categories in self.categorical_encoder.items():\n",
    "            cur_col = X.loc[:,colname].values\n",
    "            one_hots = np.eye(len(categories))\n",
    "            cats = {category: one_hots[i] for i,category in enumerate(categories)}\n",
    "            def get_cat(x):\n",
    "                return cats.get(x,None)\n",
    "            output_arr = np.vstack([get_cat(x) for x in cur_col])\n",
    "            to_concat = pd.DataFrame(output_arr,index=cur_df.index,columns=categories)\n",
    "            cur_df = pd.concat([cur_df,to_concat],axis=1)\n",
    "        return cur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_adder(df):\n",
    "    new_df = df.copy()\n",
    "    new_df[\"TotVol\"] = new_df[\"FVC\"]/new_df[\"Percent\"]\n",
    "    for patient in new_df['Patient']:\n",
    "        min_week = new_df.loc[df['Patient']==patient,'Weeks'].idxmin()\n",
    "        new_df.loc[df['Patient']==patient,\"Int_Week\"] = df.loc[min_week,'Weeks']\n",
    "        new_df.loc[df['Patient']==patient,\"Int_FVC\"] = df.loc[min_week,'FVC']\n",
    "        new_df.loc[df['Patient']==patient,\"Int_Perc\"] = df.loc[min_week,'Percent']\n",
    "        \n",
    "    new_df[\"Weeks\"] = np.minimum(new_df['Weeks'] - new_df['Int_Week'],63)\n",
    "    \n",
    "    return new_df\n",
    "    \n",
    "preproc = PreprocessData(numerical_features = [\"FVC\",\"Weeks\",\n",
    "                                               \"Age\",\n",
    "                                               \"TotVol\",\n",
    "                                              #\"Percent\",\n",
    "                                              #\"Int_Week\",\n",
    "                                              \"Int_FVC\",\n",
    "                                               #\"Int_Perc\",\n",
    "                                              \"density\",\n",
    "                                              \"HComb\",\n",
    "                                              ],\n",
    "                        categorical_encoder = {\"Sex\":[\"Male\",\"Female\"],\n",
    "                                              \"SmokingStatus\":[\"Ex-smoker\",\"Currently smokes\",\"Never smoked\"]},\n",
    "                        feature_adder=feature_adder,\n",
    "                        set_index=\"Patient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = Resize((20,64,64,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train = preproc.transform(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FVC</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>Age</th>\n",
       "      <th>TotVol</th>\n",
       "      <th>Int_FVC</th>\n",
       "      <th>density</th>\n",
       "      <th>HComb</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Ex-smoker</th>\n",
       "      <th>Currently smokes</th>\n",
       "      <th>Never smoked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patient</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID00007637202177411956430</th>\n",
       "      <td>2315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79</td>\n",
       "      <td>39.74</td>\n",
       "      <td>2315.0</td>\n",
       "      <td>51.892489</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID00007637202177411956430</th>\n",
       "      <td>2214</td>\n",
       "      <td>9.0</td>\n",
       "      <td>79</td>\n",
       "      <td>39.74</td>\n",
       "      <td>2315.0</td>\n",
       "      <td>51.892489</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID00007637202177411956430</th>\n",
       "      <td>2061</td>\n",
       "      <td>11.0</td>\n",
       "      <td>79</td>\n",
       "      <td>39.74</td>\n",
       "      <td>2315.0</td>\n",
       "      <td>51.892489</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID00007637202177411956430</th>\n",
       "      <td>2144</td>\n",
       "      <td>13.0</td>\n",
       "      <td>79</td>\n",
       "      <td>39.74</td>\n",
       "      <td>2315.0</td>\n",
       "      <td>51.892489</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID00007637202177411956430</th>\n",
       "      <td>2069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>79</td>\n",
       "      <td>39.74</td>\n",
       "      <td>2315.0</td>\n",
       "      <td>51.892489</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            FVC  Weeks  Age  TotVol  Int_FVC    density  \\\n",
       "Patient                                                                   \n",
       "ID00007637202177411956430  2315    0.0   79   39.74   2315.0  51.892489   \n",
       "ID00007637202177411956430  2214    9.0   79   39.74   2315.0  51.892489   \n",
       "ID00007637202177411956430  2061   11.0   79   39.74   2315.0  51.892489   \n",
       "ID00007637202177411956430  2144   13.0   79   39.74   2315.0  51.892489   \n",
       "ID00007637202177411956430  2069   15.0   79   39.74   2315.0  51.892489   \n",
       "\n",
       "                           HComb  Male  Female  Ex-smoker  Currently smokes  \\\n",
       "Patient                                                                       \n",
       "ID00007637202177411956430   19.7   1.0     0.0        1.0               0.0   \n",
       "ID00007637202177411956430   19.7   1.0     0.0        1.0               0.0   \n",
       "ID00007637202177411956430   19.7   1.0     0.0        1.0               0.0   \n",
       "ID00007637202177411956430   19.7   1.0     0.0        1.0               0.0   \n",
       "ID00007637202177411956430   19.7   1.0     0.0        1.0               0.0   \n",
       "\n",
       "                           Never smoked  \n",
       "Patient                                  \n",
       "ID00007637202177411956430           0.0  \n",
       "ID00007637202177411956430           0.0  \n",
       "ID00007637202177411956430           0.0  \n",
       "ID00007637202177411956430           0.0  \n",
       "ID00007637202177411956430           0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1549"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacked_image(imList):\n",
    "    return np.vstack([np.expand_dims(plt.imread(im),0).astype(np.float)\n",
    "                      for im in imList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dict = {patient_name : resize.transform([get_stacked_image([os.path.join(im_dir,patient_name,im) for im in \n",
    "                          natsorted(os.listdir(os.path.join(im_dir,patient_name)))])])\n",
    "                          for patient_name in os.listdir(im_dir)\n",
    "                             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = preprocessed_train.loc[:,'FVC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = resize.transform([get_stacked_image([os.path.join(im_dir,'ID00426637202313170790466',im) for im in \n",
    "                          natsorted(os.listdir(os.path.join(im_dir,'ID00426637202313170790466')))])])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e984b902c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in preprocessed_train.columns:\n",
    "    if col != 'FVC':\n",
    "        min_val,max_val = preprocessed_train.loc[:,col].min(),preprocessed_train.loc[:,col].max()\n",
    "        preprocessed_train[col] = (preprocessed_train[col]-min_val)/(max_val-min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ims = np.vstack([images_dict[key] for key in preprocessed_train.index])\n",
    "tabdata = preprocessed_train.drop(columns=['FVC']).values\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1549, 20, 64, 64, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = [64,64,1]\n",
    "NUM_TRAIN_EXAMPLES = len(data_ims)\n",
    "NUM_HELDOUT_EXAMPLES = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001                \n",
    "num_epochs = 75\n",
    "BATCH_SIZE = 20               \n",
    "data_dir=os.path.join('BayesianNN', 'tmp',\n",
    "                                         'bayesian_neural_network','data')                  \n",
    "model_dir=os.path.join('BayesianNN',\n",
    "                         'bayesian_neural_network')\n",
    "viz_steps=50\n",
    "num_monte_carlo=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"Creates a Keras model using the LeNet-5 architecture.\n",
    "    Returns:\n",
    "      model: Compiled Keras model.\n",
    "    \"\"\"\n",
    "  # KL divergence weighted by the number of training samples, using\n",
    "  # lambda function to pass as input to the kernel_divergence_fn on\n",
    "  # flipout layers.\n",
    "    kl_divergence_function = (lambda q, p, _: tfd.kl_divergence(q, p) /  # pylint: disable=g-long-lambda\n",
    "                            tf.cast(NUM_TRAIN_EXAMPLES, dtype=tf.float32))\n",
    "\n",
    "  # Define a LeNet-5 model using three convolutional (with max pooling)\n",
    "  # and two fully connected dense layers. We use the Flipout\n",
    "  # Monte Carlo estimator for these layers, which enables lower variance\n",
    "  # stochastic gradients than naive reparameterization.\n",
    "    \n",
    "    #tower 1\n",
    "    input0 = tf.keras.layers.Input(shape=(20,64,64,1))\n",
    "    conv0 = tfp.layers.Convolution3DFlipout(\n",
    "          6, kernel_size=5, padding='SAME',\n",
    "          kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.relu)(input0)\n",
    "    pool0 = tf.keras.layers.MaxPooling3D(\n",
    "          pool_size=[2, 2,2], strides=[2, 2,2],\n",
    "          padding='SAME')(conv0)\n",
    "    conv1 = tfp.layers.Convolution3DFlipout(\n",
    "          16, kernel_size=5, padding='SAME',\n",
    "          kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.relu)(pool0)\n",
    "    pool1 = tf.keras.layers.MaxPooling3D(\n",
    "          pool_size=[2, 2,2], strides=[2, 2,2],\n",
    "          padding='SAME')(conv1)\n",
    "    conv2 = tfp.layers.Convolution3DFlipout(\n",
    "          20, kernel_size=5, padding='SAME',\n",
    "          kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.relu)(pool1)\n",
    "    flat1 = tf.keras.layers.Flatten()(conv2)\n",
    "    dense0 = tfp.layers.DenseFlipout(3)(flat1)\n",
    "    \n",
    "    #tower 2\n",
    "    input1 = tf.keras.layers.Input(shape=(11,))\n",
    "    dense1 = tfp.layers.DenseFlipout(\n",
    "          20, kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.relu)(input1)\n",
    "    \n",
    "    #combine towers\n",
    "    concat = tf.keras.layers.concatenate([dense0,dense1])\n",
    "    dense2 = tfp.layers.DenseFlipout(\n",
    "          12, kernel_divergence_fn=kl_divergence_function,\n",
    "          activation=tf.nn.relu)(concat)\n",
    "    out = tfp.layers.DenseFlipout(\n",
    "          1, kernel_divergence_fn=kl_divergence_function)(dense2)\n",
    "  \n",
    "    model = tf.keras.Model(inputs=[input0,input1],outputs=out)\n",
    "  # Model compilation.\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "  # The Keras API will automatically add the\n",
    "  # Kullback-Leibler divergence (contained on the individual layers of\n",
    "  # the model), to the mean squared error loss, effectively\n",
    "  # calcuating the (negated) Evidence Lower Bound Loss (ELBO)\n",
    "    model.compile(optimizer, loss='mean_squared_error',\n",
    "                metrics=['mae'], experimental_run_tf_function=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot(x_list,title,savefile):\n",
    "    fig = plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Categorical Variables')\n",
    "    plt.ylabel('Predicted FVC')\n",
    "    sns.boxplot(data=x_list,orient='v')\n",
    "    plt.savefig(savefile,bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    del argv  # unused\n",
    "    #if tf.io.gfile.exists(model_dir):\n",
    "    #    tf.compat.v1.logging.warning(\n",
    "    #    'Warning: deleting old log directory at {}'.format(model_dir))\n",
    "    #    tf.io.gfile.rmtree(model_dir)\n",
    "    tf.io.gfile.makedirs(model_dir)\n",
    "    train_set, heldout_set = (data_ims[:NUM_TRAIN_EXAMPLES],\n",
    "                              tabdata[:NUM_TRAIN_EXAMPLES],\n",
    "                              labels[:NUM_TRAIN_EXAMPLES]), (data_ims[-NUM_HELDOUT_EXAMPLES:],\n",
    "                     tabdata[-NUM_TRAIN_EXAMPLES:],\n",
    "                     labels[-NUM_HELDOUT_EXAMPLES:])\n",
    "    train_seq = [(train_set[0][i*BATCH_SIZE:(i+1)*BATCH_SIZE],\n",
    "                  train_set[1][i*BATCH_SIZE:(i+1)*BATCH_SIZE],\n",
    "                 train_set[2][i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "                 for i in range(0,NUM_TRAIN_EXAMPLES//BATCH_SIZE) ]\n",
    "    heldout_seq_im =  np.vstack([heldout_set[0][i*BATCH_SIZE:(i+1)*BATCH_SIZE] \n",
    "                                 for i in range(0,NUM_HELDOUT_EXAMPLES//BATCH_SIZE)])\n",
    "    heldout_seq_tab = np.vstack([heldout_set[1][i*BATCH_SIZE:(i+1)*BATCH_SIZE] \n",
    "                                 for i in range(0,NUM_HELDOUT_EXAMPLES//BATCH_SIZE)])\n",
    "                 #heldout_set[2][i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "                    \n",
    "    #print(train_set[0].shape)\n",
    "    model = create_model()\n",
    "  \n",
    "    #model.build(input_shape=[None, BATCH_SIZE, 32, 32, 1])\n",
    "    losses = []\n",
    "    print(' ... Training convolutional neural network')\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_accuracy, epoch_loss = [], []\n",
    "        for step, (batch_x_im,batch_x_tab, batch_y) in enumerate(train_seq):\n",
    "            batch_loss, batch_accuracy = model.train_on_batch(\n",
    "          [batch_x_im,batch_x_tab], batch_y)\n",
    "            epoch_accuracy.append(batch_accuracy)\n",
    "            epoch_loss.append(batch_loss)\n",
    "\n",
    "            if (step+1) % BATCH_SIZE == 0:\n",
    "                print('Epoch: {}, Batch index: {}, '\n",
    "                      'Loss: {:.3f}, Accuracy: {:.3f}'.format(\n",
    "                          epoch, step,\n",
    "                          tf.reduce_mean(epoch_loss),\n",
    "                          tf.reduce_mean(epoch_accuracy)))\n",
    "\n",
    "            if (step+1) % viz_steps == 0:\n",
    "                # Compute log prob of heldout set by averaging draws from the model:\n",
    "                # p(heldout | train) = int_model p(heldout|model) p(model|train)\n",
    "                #                   ~= 1/n * sum_{i=1}^n p(heldout | model_i)\n",
    "                # where model_i is a draw from the posterior p(model|train).\n",
    "                print(' ... Running monte carlo inference')\n",
    "                probs = [model.predict([heldout_seq_im,heldout_seq_tab], verbose=0)\n",
    "                                  for _ in range(num_monte_carlo)]\n",
    "                \n",
    "                box_plot(probs,'Predictions',os.path.join('BayesianNN','plots','epoch{}_step{}_pred.png'.format(\n",
    "                                      epoch, step))) \n",
    "        \n",
    "                                  \n",
    "            \n",
    "        losses.append(tf.reduce_mean(epoch_loss))\n",
    "    plt.figure()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Squared Error (FVC)')\n",
    "    plt.plot(losses)\n",
    "    plt.savefig(os.path.join('BayesianNN','plots','MSE.png'),bbox_inches='tight')\n",
    "    model.save(os.path.join('BayesianNN','bayesian_neural_network'))\n",
    "    plt.close()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ... Training convolutional neural network\n",
      "Epoch: 0, Batch index: 19, Loss: 6319430.500, Accuracy: 2221.205\n",
      "Epoch: 0, Batch index: 39, Loss: 4900149.000, Accuracy: 1870.785\n",
      " ... Running monte carlo inference\n",
      "Epoch: 0, Batch index: 59, Loss: 4154869.250, Accuracy: 1668.703\n",
      "Epoch: 1, Batch index: 19, Loss: 2068600.375, Accuracy: 1108.159\n",
      "Epoch: 1, Batch index: 39, Loss: 2044373.000, Accuracy: 1106.100\n",
      " ... Running monte carlo inference\n",
      "Epoch: 1, Batch index: 59, Loss: 1964709.750, Accuracy: 1058.986\n",
      "Epoch: 2, Batch index: 19, Loss: 1617486.375, Accuracy: 918.489\n",
      "Epoch: 2, Batch index: 39, Loss: 1713547.625, Accuracy: 970.362\n",
      " ... Running monte carlo inference\n",
      "Epoch: 2, Batch index: 59, Loss: 1661902.625, Accuracy: 942.229\n",
      "Epoch: 3, Batch index: 19, Loss: 1522572.125, Accuracy: 892.550\n",
      "Epoch: 3, Batch index: 39, Loss: 1647170.375, Accuracy: 953.491\n",
      " ... Running monte carlo inference\n",
      "Epoch: 3, Batch index: 59, Loss: 1652450.250, Accuracy: 949.748\n",
      "Epoch: 4, Batch index: 19, Loss: 1487014.375, Accuracy: 910.570\n",
      "Epoch: 4, Batch index: 39, Loss: 1493044.250, Accuracy: 915.607\n",
      " ... Running monte carlo inference\n",
      "Epoch: 4, Batch index: 59, Loss: 1488001.500, Accuracy: 908.158\n",
      "Epoch: 5, Batch index: 19, Loss: 1414132.875, Accuracy: 875.159\n",
      "Epoch: 5, Batch index: 39, Loss: 1442317.750, Accuracy: 899.984\n",
      " ... Running monte carlo inference\n",
      "Epoch: 5, Batch index: 59, Loss: 1418340.250, Accuracy: 875.601\n",
      "Epoch: 6, Batch index: 19, Loss: 1212945.000, Accuracy: 803.972\n",
      "Epoch: 6, Batch index: 39, Loss: 1325368.000, Accuracy: 840.996\n",
      " ... Running monte carlo inference\n",
      "Epoch: 6, Batch index: 59, Loss: 1266575.500, Accuracy: 799.457\n",
      "Epoch: 7, Batch index: 19, Loss: 1157419.000, Accuracy: 767.048\n",
      "Epoch: 7, Batch index: 39, Loss: 1152671.000, Accuracy: 780.231\n",
      " ... Running monte carlo inference\n",
      "Epoch: 7, Batch index: 59, Loss: 1160795.125, Accuracy: 773.075\n",
      "Epoch: 8, Batch index: 19, Loss: 1153230.250, Accuracy: 794.774\n",
      "Epoch: 8, Batch index: 39, Loss: 1185974.375, Accuracy: 796.016\n",
      " ... Running monte carlo inference\n",
      "Epoch: 8, Batch index: 59, Loss: 1244966.125, Accuracy: 803.743\n",
      "Epoch: 9, Batch index: 19, Loss: 1101530.500, Accuracy: 757.276\n",
      "Epoch: 9, Batch index: 39, Loss: 1114911.750, Accuracy: 766.293\n",
      " ... Running monte carlo inference\n",
      "Epoch: 9, Batch index: 59, Loss: 1167918.625, Accuracy: 772.488\n",
      "Epoch: 10, Batch index: 19, Loss: 1011622.000, Accuracy: 698.467\n",
      "Epoch: 10, Batch index: 39, Loss: 1055868.125, Accuracy: 729.036\n",
      " ... Running monte carlo inference\n",
      "Epoch: 10, Batch index: 59, Loss: 1069843.250, Accuracy: 723.223\n",
      "Epoch: 11, Batch index: 19, Loss: 917786.625, Accuracy: 680.661\n",
      "Epoch: 11, Batch index: 39, Loss: 943991.125, Accuracy: 685.724\n",
      " ... Running monte carlo inference\n",
      "Epoch: 11, Batch index: 59, Loss: 966040.250, Accuracy: 689.164\n",
      "Epoch: 12, Batch index: 19, Loss: 910207.188, Accuracy: 669.481\n",
      "Epoch: 12, Batch index: 39, Loss: 897575.375, Accuracy: 658.274\n",
      " ... Running monte carlo inference\n",
      "Epoch: 12, Batch index: 59, Loss: 929772.250, Accuracy: 661.499\n",
      "Epoch: 13, Batch index: 19, Loss: 896043.375, Accuracy: 682.407\n",
      "Epoch: 13, Batch index: 39, Loss: 902007.625, Accuracy: 670.308\n",
      " ... Running monte carlo inference\n",
      "Epoch: 13, Batch index: 59, Loss: 908923.062, Accuracy: 659.016\n",
      "Epoch: 14, Batch index: 19, Loss: 865827.375, Accuracy: 656.771\n",
      "Epoch: 14, Batch index: 39, Loss: 855818.312, Accuracy: 646.109\n",
      " ... Running monte carlo inference\n",
      "Epoch: 14, Batch index: 59, Loss: 894659.062, Accuracy: 654.426\n",
      "Epoch: 15, Batch index: 19, Loss: 818039.250, Accuracy: 632.547\n",
      "Epoch: 15, Batch index: 39, Loss: 808767.375, Accuracy: 621.958\n",
      " ... Running monte carlo inference\n",
      "Epoch: 15, Batch index: 59, Loss: 821679.000, Accuracy: 618.855\n",
      "Epoch: 16, Batch index: 19, Loss: 764723.125, Accuracy: 597.300\n",
      "Epoch: 16, Batch index: 39, Loss: 738762.625, Accuracy: 578.058\n",
      " ... Running monte carlo inference\n",
      "Epoch: 16, Batch index: 59, Loss: 780521.625, Accuracy: 586.505\n",
      "Epoch: 17, Batch index: 19, Loss: 707670.000, Accuracy: 564.818\n",
      "Epoch: 17, Batch index: 39, Loss: 742595.375, Accuracy: 577.524\n",
      " ... Running monte carlo inference\n",
      "Epoch: 17, Batch index: 59, Loss: 753421.375, Accuracy: 574.388\n",
      "Epoch: 18, Batch index: 19, Loss: 826147.062, Accuracy: 636.027\n",
      "Epoch: 18, Batch index: 39, Loss: 809589.875, Accuracy: 621.831\n",
      " ... Running monte carlo inference\n",
      "Epoch: 18, Batch index: 59, Loss: 786640.125, Accuracy: 602.777\n",
      "Epoch: 19, Batch index: 19, Loss: 783600.125, Accuracy: 616.811\n",
      "Epoch: 19, Batch index: 39, Loss: 766667.500, Accuracy: 609.981\n",
      " ... Running monte carlo inference\n",
      "Epoch: 19, Batch index: 59, Loss: 764994.562, Accuracy: 594.221\n",
      "Epoch: 20, Batch index: 19, Loss: 755977.875, Accuracy: 584.653\n",
      "Epoch: 20, Batch index: 39, Loss: 742537.500, Accuracy: 581.560\n",
      " ... Running monte carlo inference\n",
      "Epoch: 20, Batch index: 59, Loss: 744973.438, Accuracy: 571.412\n",
      "Epoch: 21, Batch index: 19, Loss: 678965.000, Accuracy: 544.298\n",
      "Epoch: 21, Batch index: 39, Loss: 727497.375, Accuracy: 580.045\n",
      " ... Running monte carlo inference\n",
      "Epoch: 21, Batch index: 59, Loss: 723190.688, Accuracy: 564.754\n",
      "Epoch: 22, Batch index: 19, Loss: 705102.312, Accuracy: 560.202\n",
      "Epoch: 22, Batch index: 39, Loss: 719820.500, Accuracy: 562.981\n",
      " ... Running monte carlo inference\n",
      "Epoch: 22, Batch index: 59, Loss: 710311.688, Accuracy: 556.913\n",
      "Epoch: 23, Batch index: 19, Loss: 632560.688, Accuracy: 527.078\n",
      "Epoch: 23, Batch index: 39, Loss: 687742.312, Accuracy: 566.925\n",
      " ... Running monte carlo inference\n",
      "Epoch: 23, Batch index: 59, Loss: 673812.312, Accuracy: 547.486\n",
      "Epoch: 24, Batch index: 19, Loss: 726858.875, Accuracy: 569.124\n",
      "Epoch: 24, Batch index: 39, Loss: 722104.375, Accuracy: 569.941\n",
      " ... Running monte carlo inference\n",
      "Epoch: 24, Batch index: 59, Loss: 707540.688, Accuracy: 552.025\n",
      "Epoch: 25, Batch index: 19, Loss: 668120.625, Accuracy: 537.631\n",
      "Epoch: 25, Batch index: 39, Loss: 660621.375, Accuracy: 533.107\n",
      " ... Running monte carlo inference\n",
      "Epoch: 25, Batch index: 59, Loss: 651247.375, Accuracy: 523.196\n",
      "Epoch: 26, Batch index: 19, Loss: 648785.000, Accuracy: 526.442\n",
      "Epoch: 26, Batch index: 39, Loss: 655174.000, Accuracy: 534.047\n",
      " ... Running monte carlo inference\n",
      "Epoch: 26, Batch index: 59, Loss: 635518.312, Accuracy: 518.136\n",
      "Epoch: 27, Batch index: 19, Loss: 599702.812, Accuracy: 486.820\n",
      "Epoch: 27, Batch index: 39, Loss: 613157.875, Accuracy: 512.384\n",
      " ... Running monte carlo inference\n",
      "Epoch: 27, Batch index: 59, Loss: 622899.188, Accuracy: 515.341\n",
      "Epoch: 28, Batch index: 19, Loss: 607597.500, Accuracy: 506.154\n",
      "Epoch: 28, Batch index: 39, Loss: 608078.875, Accuracy: 504.631\n",
      " ... Running monte carlo inference\n",
      "Epoch: 28, Batch index: 59, Loss: 602210.625, Accuracy: 496.520\n",
      "Epoch: 29, Batch index: 19, Loss: 620807.125, Accuracy: 512.081\n",
      "Epoch: 29, Batch index: 39, Loss: 618919.812, Accuracy: 514.590\n",
      " ... Running monte carlo inference\n",
      "Epoch: 29, Batch index: 59, Loss: 617343.125, Accuracy: 508.843\n",
      "Epoch: 30, Batch index: 19, Loss: 600200.188, Accuracy: 501.777\n",
      "Epoch: 30, Batch index: 39, Loss: 580374.250, Accuracy: 486.428\n",
      " ... Running monte carlo inference\n",
      "Epoch: 30, Batch index: 59, Loss: 565113.312, Accuracy: 477.191\n",
      "Epoch: 31, Batch index: 19, Loss: 556198.125, Accuracy: 460.180\n",
      "Epoch: 31, Batch index: 39, Loss: 550500.750, Accuracy: 466.881\n",
      " ... Running monte carlo inference\n",
      "Epoch: 31, Batch index: 59, Loss: 564639.000, Accuracy: 473.291\n",
      "Epoch: 32, Batch index: 19, Loss: 579776.375, Accuracy: 475.963\n",
      "Epoch: 32, Batch index: 39, Loss: 548947.938, Accuracy: 458.744\n",
      " ... Running monte carlo inference\n",
      "Epoch: 32, Batch index: 59, Loss: 536812.188, Accuracy: 451.541\n",
      "Epoch: 33, Batch index: 19, Loss: 537055.938, Accuracy: 457.847\n",
      "Epoch: 33, Batch index: 39, Loss: 530156.312, Accuracy: 455.002\n",
      " ... Running monte carlo inference\n",
      "Epoch: 33, Batch index: 59, Loss: 518284.531, Accuracy: 445.454\n",
      "Epoch: 34, Batch index: 19, Loss: 511417.312, Accuracy: 431.062\n",
      "Epoch: 34, Batch index: 39, Loss: 503901.406, Accuracy: 431.643\n",
      " ... Running monte carlo inference\n",
      "Epoch: 34, Batch index: 59, Loss: 495635.062, Accuracy: 428.271\n",
      "Epoch: 35, Batch index: 19, Loss: 536130.375, Accuracy: 454.732\n",
      "Epoch: 35, Batch index: 39, Loss: 513960.438, Accuracy: 447.661\n",
      " ... Running monte carlo inference\n",
      "Epoch: 35, Batch index: 59, Loss: 507680.188, Accuracy: 440.476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Batch index: 19, Loss: 480877.062, Accuracy: 419.380\n",
      "Epoch: 36, Batch index: 39, Loss: 477544.500, Accuracy: 420.760\n",
      " ... Running monte carlo inference\n",
      "Epoch: 36, Batch index: 59, Loss: 479291.406, Accuracy: 420.836\n",
      "Epoch: 37, Batch index: 19, Loss: 497216.000, Accuracy: 430.726\n",
      "Epoch: 37, Batch index: 39, Loss: 478717.562, Accuracy: 417.355\n",
      " ... Running monte carlo inference\n",
      "Epoch: 37, Batch index: 59, Loss: 479536.562, Accuracy: 419.494\n",
      "Epoch: 38, Batch index: 19, Loss: 459448.188, Accuracy: 400.742\n",
      "Epoch: 38, Batch index: 39, Loss: 437064.656, Accuracy: 393.794\n",
      " ... Running monte carlo inference\n",
      "Epoch: 38, Batch index: 59, Loss: 438563.219, Accuracy: 395.331\n",
      "Epoch: 39, Batch index: 19, Loss: 484803.344, Accuracy: 430.422\n",
      "Epoch: 39, Batch index: 39, Loss: 457475.656, Accuracy: 413.162\n",
      " ... Running monte carlo inference\n",
      "Epoch: 39, Batch index: 59, Loss: 448132.000, Accuracy: 406.786\n",
      "Epoch: 40, Batch index: 19, Loss: 501754.344, Accuracy: 435.799\n",
      "Epoch: 40, Batch index: 39, Loss: 459144.188, Accuracy: 413.289\n",
      " ... Running monte carlo inference\n",
      "Epoch: 40, Batch index: 59, Loss: 451137.344, Accuracy: 407.639\n",
      "Epoch: 41, Batch index: 19, Loss: 461151.656, Accuracy: 415.108\n",
      "Epoch: 41, Batch index: 39, Loss: 440135.812, Accuracy: 398.805\n",
      " ... Running monte carlo inference\n",
      "Epoch: 41, Batch index: 59, Loss: 437048.531, Accuracy: 399.936\n",
      "Epoch: 42, Batch index: 19, Loss: 458993.938, Accuracy: 397.707\n",
      "Epoch: 42, Batch index: 39, Loss: 428771.156, Accuracy: 378.964\n",
      " ... Running monte carlo inference\n",
      "Epoch: 42, Batch index: 59, Loss: 433270.656, Accuracy: 390.798\n",
      "Epoch: 43, Batch index: 19, Loss: 422335.656, Accuracy: 385.260\n",
      "Epoch: 43, Batch index: 39, Loss: 397189.312, Accuracy: 367.222\n",
      " ... Running monte carlo inference\n",
      "Epoch: 43, Batch index: 59, Loss: 402921.188, Accuracy: 374.382\n",
      "Epoch: 44, Batch index: 19, Loss: 423600.656, Accuracy: 381.948\n",
      "Epoch: 44, Batch index: 39, Loss: 397371.750, Accuracy: 368.155\n",
      " ... Running monte carlo inference\n",
      "Epoch: 44, Batch index: 59, Loss: 396891.219, Accuracy: 369.112\n",
      "Epoch: 45, Batch index: 19, Loss: 476197.656, Accuracy: 421.953\n",
      "Epoch: 45, Batch index: 39, Loss: 435696.312, Accuracy: 397.234\n",
      " ... Running monte carlo inference\n",
      "Epoch: 45, Batch index: 59, Loss: 428510.062, Accuracy: 392.373\n",
      "Epoch: 46, Batch index: 19, Loss: 495531.406, Accuracy: 433.238\n",
      "Epoch: 46, Batch index: 39, Loss: 442646.688, Accuracy: 400.678\n",
      " ... Running monte carlo inference\n",
      "Epoch: 46, Batch index: 59, Loss: 425934.000, Accuracy: 392.162\n",
      "Epoch: 47, Batch index: 19, Loss: 459560.594, Accuracy: 420.493\n",
      "Epoch: 47, Batch index: 39, Loss: 445836.750, Accuracy: 411.947\n",
      " ... Running monte carlo inference\n",
      "Epoch: 47, Batch index: 59, Loss: 436473.062, Accuracy: 405.372\n",
      "Epoch: 48, Batch index: 19, Loss: 402423.938, Accuracy: 368.030\n",
      "Epoch: 48, Batch index: 39, Loss: 380337.938, Accuracy: 349.105\n",
      " ... Running monte carlo inference\n",
      "Epoch: 48, Batch index: 59, Loss: 385325.281, Accuracy: 353.287\n",
      "Epoch: 49, Batch index: 19, Loss: 430960.656, Accuracy: 389.700\n",
      "Epoch: 49, Batch index: 39, Loss: 431777.312, Accuracy: 394.886\n",
      " ... Running monte carlo inference\n",
      "Epoch: 49, Batch index: 59, Loss: 414092.938, Accuracy: 381.840\n",
      "Epoch: 50, Batch index: 19, Loss: 458134.812, Accuracy: 407.578\n",
      "Epoch: 50, Batch index: 39, Loss: 423852.344, Accuracy: 380.591\n",
      " ... Running monte carlo inference\n",
      "Epoch: 50, Batch index: 59, Loss: 427340.812, Accuracy: 388.741\n",
      "Epoch: 51, Batch index: 19, Loss: 444956.906, Accuracy: 403.166\n",
      "Epoch: 51, Batch index: 39, Loss: 418871.688, Accuracy: 387.617\n",
      " ... Running monte carlo inference\n",
      "Epoch: 51, Batch index: 59, Loss: 415808.656, Accuracy: 384.521\n",
      "Epoch: 52, Batch index: 19, Loss: 475610.000, Accuracy: 431.130\n",
      "Epoch: 52, Batch index: 39, Loss: 444532.344, Accuracy: 404.108\n",
      " ... Running monte carlo inference\n",
      "Epoch: 52, Batch index: 59, Loss: 436702.719, Accuracy: 400.180\n",
      "Epoch: 53, Batch index: 19, Loss: 518213.250, Accuracy: 463.120\n",
      "Epoch: 53, Batch index: 39, Loss: 459510.562, Accuracy: 417.204\n",
      " ... Running monte carlo inference\n",
      "Epoch: 53, Batch index: 59, Loss: 434287.531, Accuracy: 398.826\n",
      "Epoch: 54, Batch index: 19, Loss: 469035.656, Accuracy: 426.217\n",
      "Epoch: 54, Batch index: 39, Loss: 405269.312, Accuracy: 373.706\n",
      " ... Running monte carlo inference\n",
      "Epoch: 54, Batch index: 59, Loss: 394639.969, Accuracy: 366.438\n",
      "Epoch: 55, Batch index: 19, Loss: 390149.250, Accuracy: 363.879\n",
      "Epoch: 55, Batch index: 39, Loss: 362341.594, Accuracy: 336.498\n",
      " ... Running monte carlo inference\n",
      "Epoch: 55, Batch index: 59, Loss: 371577.031, Accuracy: 348.688\n",
      "Epoch: 56, Batch index: 19, Loss: 382689.062, Accuracy: 358.314\n",
      "Epoch: 56, Batch index: 39, Loss: 352807.125, Accuracy: 331.883\n",
      " ... Running monte carlo inference\n",
      "Epoch: 56, Batch index: 59, Loss: 359521.781, Accuracy: 342.863\n",
      "Epoch: 57, Batch index: 19, Loss: 361775.938, Accuracy: 336.624\n",
      "Epoch: 57, Batch index: 39, Loss: 341269.906, Accuracy: 315.990\n",
      " ... Running monte carlo inference\n",
      "Epoch: 57, Batch index: 59, Loss: 339908.781, Accuracy: 320.440\n",
      "Epoch: 58, Batch index: 19, Loss: 353995.250, Accuracy: 329.257\n",
      "Epoch: 58, Batch index: 39, Loss: 343008.562, Accuracy: 318.596\n",
      " ... Running monte carlo inference\n",
      "Epoch: 58, Batch index: 59, Loss: 334284.062, Accuracy: 312.837\n",
      "Epoch: 59, Batch index: 19, Loss: 339496.500, Accuracy: 312.231\n",
      "Epoch: 59, Batch index: 39, Loss: 333429.156, Accuracy: 311.118\n",
      " ... Running monte carlo inference\n",
      "Epoch: 59, Batch index: 59, Loss: 323786.656, Accuracy: 303.204\n",
      "Epoch: 60, Batch index: 19, Loss: 313900.156, Accuracy: 292.779\n",
      "Epoch: 60, Batch index: 39, Loss: 319423.750, Accuracy: 299.701\n",
      " ... Running monte carlo inference\n",
      "Epoch: 60, Batch index: 59, Loss: 308351.875, Accuracy: 287.833\n",
      "Epoch: 61, Batch index: 19, Loss: 315337.031, Accuracy: 285.178\n",
      "Epoch: 61, Batch index: 39, Loss: 309727.438, Accuracy: 286.122\n",
      " ... Running monte carlo inference\n",
      "Epoch: 61, Batch index: 59, Loss: 301674.125, Accuracy: 277.926\n",
      "Epoch: 62, Batch index: 19, Loss: 301467.031, Accuracy: 271.444\n",
      "Epoch: 62, Batch index: 39, Loss: 313618.000, Accuracy: 287.342\n",
      " ... Running monte carlo inference\n",
      "Epoch: 62, Batch index: 59, Loss: 299924.406, Accuracy: 275.626\n",
      "Epoch: 63, Batch index: 19, Loss: 295131.812, Accuracy: 262.167\n",
      "Epoch: 63, Batch index: 39, Loss: 308390.312, Accuracy: 285.424\n",
      " ... Running monte carlo inference\n",
      "Epoch: 63, Batch index: 59, Loss: 297487.594, Accuracy: 273.345\n",
      "Epoch: 64, Batch index: 19, Loss: 283703.094, Accuracy: 255.762\n",
      "Epoch: 64, Batch index: 39, Loss: 302116.125, Accuracy: 286.724\n",
      " ... Running monte carlo inference\n",
      "Epoch: 64, Batch index: 59, Loss: 290713.531, Accuracy: 270.922\n",
      "Epoch: 65, Batch index: 19, Loss: 276315.969, Accuracy: 243.153\n",
      "Epoch: 65, Batch index: 39, Loss: 289300.000, Accuracy: 270.294\n",
      " ... Running monte carlo inference\n",
      "Epoch: 65, Batch index: 59, Loss: 277887.688, Accuracy: 253.793\n",
      "Epoch: 66, Batch index: 19, Loss: 290879.312, Accuracy: 267.890\n",
      "Epoch: 66, Batch index: 39, Loss: 289967.500, Accuracy: 271.530\n",
      " ... Running monte carlo inference\n",
      "Epoch: 66, Batch index: 59, Loss: 280662.719, Accuracy: 260.782\n",
      "Epoch: 67, Batch index: 19, Loss: 269318.156, Accuracy: 245.671\n",
      "Epoch: 67, Batch index: 39, Loss: 275937.531, Accuracy: 261.081\n",
      " ... Running monte carlo inference\n",
      "Epoch: 67, Batch index: 59, Loss: 270519.125, Accuracy: 251.876\n",
      "Epoch: 68, Batch index: 19, Loss: 277299.594, Accuracy: 250.318\n",
      "Epoch: 68, Batch index: 39, Loss: 285890.562, Accuracy: 267.098\n",
      " ... Running monte carlo inference\n",
      "Epoch: 68, Batch index: 59, Loss: 278835.688, Accuracy: 257.156\n",
      "Epoch: 69, Batch index: 19, Loss: 291893.438, Accuracy: 264.743\n",
      "Epoch: 69, Batch index: 39, Loss: 287195.406, Accuracy: 267.198\n",
      " ... Running monte carlo inference\n",
      "Epoch: 69, Batch index: 59, Loss: 274889.156, Accuracy: 251.706\n",
      "Epoch: 70, Batch index: 19, Loss: 276016.000, Accuracy: 247.061\n",
      "Epoch: 70, Batch index: 39, Loss: 285835.156, Accuracy: 267.238\n",
      " ... Running monte carlo inference\n",
      "Epoch: 70, Batch index: 59, Loss: 272629.531, Accuracy: 247.750\n",
      "Epoch: 71, Batch index: 19, Loss: 289144.750, Accuracy: 258.259\n",
      "Epoch: 71, Batch index: 39, Loss: 279039.344, Accuracy: 254.682\n",
      " ... Running monte carlo inference\n",
      "Epoch: 71, Batch index: 59, Loss: 268466.656, Accuracy: 241.484\n",
      "Epoch: 72, Batch index: 19, Loss: 277106.156, Accuracy: 249.872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72, Batch index: 39, Loss: 280233.562, Accuracy: 257.079\n",
      " ... Running monte carlo inference\n",
      "Epoch: 72, Batch index: 59, Loss: 268259.688, Accuracy: 244.666\n",
      "Epoch: 73, Batch index: 19, Loss: 263470.938, Accuracy: 238.443\n",
      "Epoch: 73, Batch index: 39, Loss: 287413.531, Accuracy: 268.652\n",
      " ... Running monte carlo inference\n",
      "Epoch: 73, Batch index: 59, Loss: 276405.500, Accuracy: 254.720\n",
      "Epoch: 74, Batch index: 19, Loss: 273629.938, Accuracy: 253.824\n",
      "Epoch: 74, Batch index: 39, Loss: 273758.750, Accuracy: 256.501\n",
      " ... Running monte carlo inference\n",
      "Epoch: 74, Batch index: 59, Loss: 267446.062, Accuracy: 247.873\n",
      "INFO:tensorflow:Assets written to: BayesianNN\\bayesian_neural_network\\assets\n"
     ]
    }
   ],
   "source": [
    "main([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.close()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
